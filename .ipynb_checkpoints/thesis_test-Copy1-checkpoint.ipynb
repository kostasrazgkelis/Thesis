{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54eabc84-d793-4183-920d-ac4f20ab2902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jellyfish in /opt/conda/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: faker in /opt/conda/lib/python3.11/site-packages (37.1.0)\n",
      "Requirement already satisfied: tzdata in /opt/conda/lib/python3.11/site-packages (from faker) (2023.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install jellyfish\n",
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7fa1b45-7b04-4cc2-a017-5cfbf9ffec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import jellyfish\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import os\n",
    "import math\n",
    "from itertools import combinations, product\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from collections import defaultdict\n",
    "from packages.generateDataSets import SyntheticMatcherDataset\n",
    "from packages.calculateStatistics import DatasetEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a756b54-8c72-4213-9683-0f2a3ea10c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "263d1dfd-42da-463a-9eed-86cf9556e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    def __init__(self, df1: pd.DataFrame, \n",
    "                 df2: pd.DataFrame, \n",
    "                 matchColumn: str, \n",
    "                 on: List = [],\n",
    "                 method: str = 'column', \n",
    "                 threshold: float  = 0.6):\n",
    "        self.df1 = df1\n",
    "        self.df2 = df2\n",
    "        self.on = on\n",
    "        self.threshold = threshold\n",
    "\n",
    "        if method not in [\"concat\", \"column\"]:\n",
    "            raise ValueError(f\"Method '{method}' is not correct.\")\n",
    "        self.method = method\n",
    "\n",
    "    \n",
    "        if matchColumn not in self.df1.columns or matchColumn not in self.df2.columns:\n",
    "            raise ValueError(f\"Column '{matchColumn}' is not found in both DataFrames.\")\n",
    "        self.matchColumn = matchColumn\n",
    "        \n",
    "        self.groundTruth = None\n",
    "        self.totalMatches = None        \n",
    "    \n",
    "    def setGroundTruth(self):\n",
    "        \"\"\"Sets the ground truth based on matching 'id' columns.\"\"\"\n",
    "        self.groundTruth = np.intersect1d(self.df1[self.matchColumn], self.df2[self.matchColumn])\n",
    "\n",
    "    def soundexDfs(self):\n",
    "        \"\"\"Apply soundex transformation to non-id columns.\"\"\"\n",
    "        for df in [self.df1, self.df2]:\n",
    "            for col_name in df.columns:\n",
    "                if col_name != self.matchColumn:\n",
    "                    df[col_name] = df[col_name].apply(lambda x: jellyfish.soundex(str(x)))\n",
    "\n",
    "            if self.method == 'concat':\n",
    "                non_match_columns = [col for col in df.columns if col != self.matchColumn]\n",
    "                df['concatenated'] = df[non_match_columns].apply(lambda row: ''.join(row.astype(str)), axis=1)\n",
    "                df.drop(columns=non_match_columns, inplace=True)\n",
    "\n",
    "    def setTotalMatches(self):\n",
    "        \"\"\"Sets the total matches based on merged DataFrames.\"\"\"\n",
    "        \n",
    "        # if self.method == 'concat':\n",
    "        #     self.totalMatches = self.df1.merge(self.df2, how=\"inner\", on=['concatenated']).to_numpy()\n",
    "        # else:   \n",
    "        #     self.totalMatches = self.df1.merge(self.df2, how=\"outer\", on=self.on + [self.matchColumn]).to_numpy()\n",
    "\n",
    "        self.totalMatches =  self.df1.merge(pd.concat([self.df1, self.df2]), how='outer', on=self.on)[[\"0_y\"] + self.on]\n",
    "        self.totalMatches.rename(columns={'0_y': self.matchColumn}, inplace=True)\n",
    "        \n",
    "    def printStatistics(self):\n",
    "        \"\"\"Print statistics (True Positives, False Positives, Precision).\"\"\"\n",
    "        myStatistics = self.Statistics(groundTruth=self.groundTruth, \n",
    "                                       totalMatches=self.totalMatches, \n",
    "                                       threshold=self.threshold, \n",
    "                                       on=self.on, \n",
    "                                       matchColumn=self.matchColumn)\n",
    "        myStatistics.calculate()\n",
    "\n",
    "    # Inner class Statistics\n",
    "    class Statistics:\n",
    "        def __init__(self,\n",
    "                     groundTruth: pd.DataFrame, \n",
    "                     totalMatches: pd.DataFrame, \n",
    "                     threshold : float = 0.8,\n",
    "                     matchColumn: str | int = 1,\n",
    "                     on: List =[]):\n",
    "            self.groundTruth = pd.DataFrame(groundTruth)\n",
    "            self.totalMatches = pd.DataFrame(totalMatches)\n",
    "            self.threshold = threshold\n",
    "            self.matchColumn = matchColumn\n",
    "            self.on = on\n",
    "\n",
    "            self._setThresholdValues()\n",
    "            \n",
    "        def calculate(self):\n",
    "            # self.result = self.totalMatches.groupby(self.matchColumn)\\\n",
    "            #         .filter(lambda x : len(x) >=2)\\\n",
    "            #         .groupby(self.matchColumn)\\\n",
    "            #         .apply(lambda x: x.iloc[:, 1:].apply(lambda x: x.nunique() == 1)).sum(axis=1)\n",
    "\n",
    "            duplicates = self.totalMatches[self.totalMatches[[1,2,3,4,5]].duplicated(keep=False)].sort_values(by=[1,2,3,4,5])\n",
    "        \n",
    "            # Function to check if two rows match at least 3/5 columns\n",
    "            def is_duplicate(row1, row2):\n",
    "                return sum(row1 == row2) >=  self.matchingRows  # At least 3 matches out of 5\n",
    "\n",
    "            # print(duplicates)\n",
    "            \n",
    "            duplicate_pairs = []\n",
    "            # Find duplicates\n",
    "            for i in range(len(duplicates)):\n",
    "                for j in range(i + 1, len(duplicates)):  # Compare only unique pairs\n",
    "                    if is_duplicate(duplicates.iloc[i, 1:], duplicates.iloc[j, 1:]):\n",
    "                        duplicate_pairs.append((i, j, duplicates.iloc[i, 0] == duplicates.iloc[j, 0]))  # Store (index1, index2, same_id)\n",
    "\n",
    "            # Count same ID and different ID duplicates\n",
    "            tp = sum(1 for _, _, same_id in duplicate_pairs if same_id)\n",
    "            fp = len(duplicate_pairs) - same_id_count\n",
    "            fn = self.groundTruth.size - tp\n",
    "            \n",
    "            precision = tp / (tp + fp) if tp + fp != 0 else 0 \n",
    "            recall = tp / (tp + fn)  if tp + fn != 0 else 0\n",
    "            f1_score = (2 * precision * recall) / (precision + recall)\n",
    "            \n",
    "            print(\"Total Possible Mathces:\", self.groundTruth.size)\n",
    "            print(\"True Positives (TP):\", tp)\n",
    "            print(\"False Positives (FP):\", fp)\n",
    "            print(\"False Negatives (FN):\", fn)\n",
    "            print(\"Precision:\", f\"{precision:.4f}\")\n",
    "            print(\"Recall:\", f\"{recall:.4f}\")\n",
    "            print(\"F1-score:\", f\"{f1_score:.4f}\")\n",
    "\n",
    "        def _matchingAlgorithm(self, group):\n",
    "            return group.nunique() == 1\n",
    "            \n",
    "        def _setThresholdValues(self) -> List:\n",
    "            size = len(self.totalMatches.columns) - 1\n",
    "            limit = math.floor(self.threshold * size)\n",
    "            \n",
    "            print(f\"We accept at least {limit}/{size} as matches!\") \n",
    "            self.matchingRows = limit\n",
    "            # return [i for i in range(size, limit , -1)]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d804a1c-5175-4398-b9a5-30b12ac8386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH  =  \"data/\"\n",
    "\n",
    "df1 = pd.read_csv(os.path.join(PATH, 'df1.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "df2 = pd.read_csv(os.path.join(PATH, 'df2.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "\n",
    "# Run pipeline and see statistics\n",
    "pipeline = MyClass(df1, df2, matchColumn=0, on=[1,2,3,4,5], method=\"column\", threshold = 0.6) #  --> this means at least 3/5 of the fields must match \n",
    "pipeline.setGroundTruth()\n",
    "pipeline.soundexDfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12492b90-54e7-4707-9c6d-cf1070265fdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: {}\n",
      "Ground Truth Size: 25000\n",
      "True Positives: 19036\n",
      "False Positives: 17830\n",
      "False Negatives: 5964\n",
      "Precision: 0.5164\n",
      "Recall: 0.7614\n",
      "Elapsed Time: 81137.75 seconds\n"
     ]
    }
   ],
   "source": [
    "evaluator = DatasetEvaluator(pipeline.df1, pipeline.df2, threshold=3)\n",
    "evaluator.evaluate()\n",
    "evaluator.printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3013db6-b66b-491b-bfe2-d07daf5e4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 -> df2\n",
    "thresh = 3\n",
    "Expected: {}\n",
    "Ground Truth Size: 25000\n",
    "True Positives: 19036\n",
    "False Positives: 17830\n",
    "False Negatives: 5964\n",
    "Precision: 0.5164\n",
    "Recall: 0.7614\n",
    "Elapsed Time: 81137.75 seconds\n",
    "\n",
    "\n",
    "# df1 -> df5\n",
    "thresh = 2\n",
    "Expected: {}\n",
    "Ground Truth Size: 25000\n",
    "True Positives: 24977\n",
    "False Positives: 74055\n",
    "False Negatives: 23\n",
    "Precision: 0.2522\n",
    "Recall: 0.9991\n",
    "Elapsed Time: 4861.54 seconds\n",
    "\n",
    "# df1 -> df5\n",
    "thresh = 3\n",
    "Expected: {}\n",
    "Ground Truth Size: 25000\n",
    "True Positives: 19125\n",
    "False Positives: 16323\n",
    "False Negatives: 5875\n",
    "Precision: 0.5395\n",
    "Recall: 0.7650\n",
    "Elapsed Time: 80256.47 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a3d4cf-36e3-4b0e-96eb-5f4923a1274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import jellyfish\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import os\n",
    "import math\n",
    "from itertools import combinations, product\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from collections import defaultdict\n",
    "from packages.generateDataSets import SyntheticMatcherDataset\n",
    "from packages.calculateStatistics import DatasetEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "603541e9-4f75-435c-86aa-7e45489ef7b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create two datasets with slight variations\n",
    "# Data have 3 matches and one \n",
    "data1 = {\n",
    "    0: [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "    1: [\"Kostas\", \"Maria\", \"John\", \"Sophia\", \"George\", \"Eleni\", \"Michael\", \"Anna\", \"Chris\", \"Dimitris\"],\n",
    "    2: [\"Razgkelis\", \"Papadopoulos\", \"Smith\", \"Johnson\", \"Pavlou\", \"Nikolaou\", \"Brown\", \"Miller\", \"Taylor\", \"Andreas\"],\n",
    "    3: [\"Orestiada\", \"Thessaloniki\", \"Grevena\", \"Athina\", \"Aleksandroupoli\", \"Giannena\", \"Larissa\", \"Komotini\", \"Trikala\", \"Kozani\"],\n",
    "    4: ['Jennifer Lights', 'Brandon Lakes', 'Aguilar Stravenue', 'Richardson Ferry', 'Freeman Way', \n",
    "        'Gabrielle Underpass', 'Burns Summit', 'Heather Village', 'Jamie Common', 'Greg Lock'],\n",
    "    5:  ['Cooper and Sons', 'Pope LLC', 'Fowler-Smith', 'Torres PLC', 'Jones LLC', 'White, Duncan and Robinson', 'Hayden Inc', \n",
    "         'Wilson and Sons', 'Peterson, Smith and Robinson','Hudson, Phelps and Day'],\n",
    "    \n",
    "}\n",
    "\n",
    "data2 = {\n",
    "    0: [101, 202, 203, 204, 205, 206, 207, 208, 209, 110],\n",
    "    1: [\"Kistas\", \"Maria\", \"John\", \"Sophasdia\", \"Giorge\", \"Elendsi\", \"Micheal\", \"Ana\", \"Khris\", \"Dimtris\"],\n",
    "    2: [\"Rozgkliiis\", \"Papadopoulos\", \"Smith\", \"Johnson\", \"Pavlodvu\", \"Nikolaou\", \"Batrrroun\", \"antMiler\", \"Tttayloor\", \"Andres\"],\n",
    "    3: [\"Orestiada\", \"Thessaloniki\", \"Grevena\", \"Athina\", \"Aleksandrouasdpoli\", \"Gianasdna\", \"Larasdissa\", \"Komasdini\", \"Trsadala\", \"Koxani\"],\n",
    "    4: [\"Jnnfer Lights\", 'Brandon Lakes', 'Aguilar Stravenue', 'RichardasasdaFerry', 'Freasdeman Way', 'Gabrielle Underpass', 'Burasdas mmit', 'Heatasasdllage', 'JamasdCommon', 'Grg Lck'],\n",
    "    5:  ['Cpeeer and ons', 'Pope LLC', 'Fowler-Smith', 'Torvasd PLC', 'Jonasda LLC', 'Whitasddvuncan and Robinson', 'Hayasdasv Inc', \n",
    "         'Wasdvand Sons', 'Petersosdvaith and Robinson','Htsn, Phelps and Day'],\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d6b22753-5166-46e7-b4d2-b0875bc3e1e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert to DataFrame\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Run pipeline and see statistics\n",
    "pipeline = MyClass(df1, df2, matchColumn=0, on=[1, 2, 3, 4, 5], threshold=0.4)\n",
    "pipeline.setGroundTruth()\n",
    "pipeline.soundexDfs()\n",
    "pipeline.setTotalMatches()\n",
    "# pipeline.printStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e61a9ab-5dfa-42af-930f-5322c13c0b3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m PATH  \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m), header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)[[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m]]\n\u001b[1;32m      4\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m), header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)[[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m]]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run pipeline and see statistics\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "PATH  =  \"data/\"\n",
    "\n",
    "df1 = pd.read_csv(os.path.join(PATH, 'df1.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "df2 = pd.read_csv(os.path.join(PATH, 'df2.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "\n",
    "# Run pipeline and see statistics\n",
    "pipeline = MyClass(df1, df2, matchColumn=0, on=[1,2,3,4,5], method=\"column\", threshold = 0.6) #  --> this means at least 3/5 of the fields must match \n",
    "pipeline.setGroundTruth()\n",
    "pipeline.soundexDfs()\n",
    "\n",
    "evaluator = DatasetEvaluator(pipeline.df1, pipeline.df2, expected, threshold=3)\n",
    "evaluator.evaluate()\n",
    "evaluator.printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37fcd5ed-4335-4743-84b1-f40ee90eb084",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m DatasetEvaluator(pipeline\u001b[38;5;241m.\u001b[39mdf1, pipeline\u001b[38;5;241m.\u001b[39mdf2, \u001b[43mexpected\u001b[49m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m      3\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mprintResults()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'expected' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "417a7d24-9413-4a66-9007-b0000707ef6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.293463888888887"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "80256.47/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a4547-5419-4190-b7a9-56f3d8820988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
