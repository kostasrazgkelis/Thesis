{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54eabc84-d793-4183-920d-ac4f20ab2902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jellyfish\n",
      "  Downloading jellyfish-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
      "Downloading jellyfish-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (356 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m356.9/356.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jellyfish\n",
      "Successfully installed jellyfish-1.2.0\n",
      "Collecting faker\n",
      "  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tzdata in /opt/conda/lib/python3.11/site-packages (from faker) (2023.3)\n",
      "Downloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faker\n",
      "Successfully installed faker-37.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jellyfish\n",
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fa1b45-7b04-4cc2-a017-5cfbf9ffec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import jellyfish\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import os\n",
    "import math\n",
    "from itertools import combinations, product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263d1dfd-42da-463a-9eed-86cf9556e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    def __init__(self, df1: pd.DataFrame, \n",
    "                 df2: pd.DataFrame, \n",
    "                 matchColumn: str, \n",
    "                 on: List = [],\n",
    "                 method: str = 'column', \n",
    "                 threshold: float  = 0.6):\n",
    "        self.df1 = df1\n",
    "        self.df2 = df2\n",
    "        self.on = on\n",
    "        self.threshold = threshold\n",
    "\n",
    "        if method not in [\"concat\", \"column\"]:\n",
    "            raise ValueError(f\"Method '{method}' is not correct.\")\n",
    "        self.method = method\n",
    "\n",
    "    \n",
    "        if matchColumn not in self.df1.columns or matchColumn not in self.df2.columns:\n",
    "            raise ValueError(f\"Column '{matchColumn}' is not found in both DataFrames.\")\n",
    "        self.matchColumn = matchColumn\n",
    "        \n",
    "        self.groundTruth = None\n",
    "        self.totalMatches = None        \n",
    "    \n",
    "    def setGroundTruth(self):\n",
    "        \"\"\"Sets the ground truth based on matching 'id' columns.\"\"\"\n",
    "        self.groundTruth = np.intersect1d(self.df1[self.matchColumn], self.df2[self.matchColumn])\n",
    "\n",
    "    def soundexDfs(self):\n",
    "        \"\"\"Apply soundex transformation to non-id columns.\"\"\"\n",
    "        for df in [self.df1, self.df2]:\n",
    "            for col_name in df.columns:\n",
    "                if col_name != self.matchColumn:\n",
    "                    df[col_name] = df[col_name].apply(lambda x: jellyfish.soundex(str(x)))\n",
    "\n",
    "            if self.method == 'concat':\n",
    "                non_match_columns = [col for col in df.columns if col != self.matchColumn]\n",
    "                df['concatenated'] = df[non_match_columns].apply(lambda row: ''.join(row.astype(str)), axis=1)\n",
    "                df.drop(columns=non_match_columns, inplace=True)\n",
    "\n",
    "    def setTotalMatches(self):\n",
    "        \"\"\"Sets the total matches based on merged DataFrames.\"\"\"\n",
    "        \n",
    "        # if self.method == 'concat':\n",
    "        #     self.totalMatches = self.df1.merge(self.df2, how=\"inner\", on=['concatenated']).to_numpy()\n",
    "        # else:   \n",
    "        #     self.totalMatches = self.df1.merge(self.df2, how=\"outer\", on=self.on + [self.matchColumn]).to_numpy()\n",
    "\n",
    "        self.totalMatches =  self.df1.merge(pd.concat([self.df1, self.df2]), how='outer', on=self.on)[[\"0_y\"] + self.on]\n",
    "        self.totalMatches.rename(columns={'0_y': self.matchColumn}, inplace=True)\n",
    "        \n",
    "    def printStatistics(self):\n",
    "        \"\"\"Print statistics (True Positives, False Positives, Precision).\"\"\"\n",
    "        myStatistics = self.Statistics(groundTruth=self.groundTruth, \n",
    "                                       totalMatches=self.totalMatches, \n",
    "                                       threshold=self.threshold, \n",
    "                                       on=self.on, \n",
    "                                       matchColumn=self.matchColumn)\n",
    "        myStatistics.calculate()\n",
    "\n",
    "    # Inner class Statistics\n",
    "    class Statistics:\n",
    "        def __init__(self,\n",
    "                     groundTruth: pd.DataFrame, \n",
    "                     totalMatches: pd.DataFrame, \n",
    "                     threshold : float = 0.8,\n",
    "                     matchColumn: str | int = 1,\n",
    "                     on: List =[]):\n",
    "            self.groundTruth = pd.DataFrame(groundTruth)\n",
    "            self.totalMatches = pd.DataFrame(totalMatches)\n",
    "            self.threshold = threshold\n",
    "            self.matchColumn = matchColumn\n",
    "            self.on = on\n",
    "\n",
    "            self._setThresholdValues()\n",
    "            \n",
    "        def calculate(self):\n",
    "            # self.result = self.totalMatches.groupby(self.matchColumn)\\\n",
    "            #         .filter(lambda x : len(x) >=2)\\\n",
    "            #         .groupby(self.matchColumn)\\\n",
    "            #         .apply(lambda x: x.iloc[:, 1:].apply(lambda x: x.nunique() == 1)).sum(axis=1)\n",
    "\n",
    "            duplicates = self.totalMatches[self.totalMatches[[1,2,3,4,5]].duplicated(keep=False)].sort_values(by=[1,2,3,4,5])\n",
    "        \n",
    "            # Function to check if two rows match at least 3/5 columns\n",
    "            def is_duplicate(row1, row2):\n",
    "                return sum(row1 == row2) >=  self.matchingRows  # At least 3 matches out of 5\n",
    "\n",
    "            # print(duplicates)\n",
    "            \n",
    "            duplicate_pairs = []\n",
    "            # Find duplicates\n",
    "            for i in range(len(duplicates)):\n",
    "                for j in range(i + 1, len(duplicates)):  # Compare only unique pairs\n",
    "                    if is_duplicate(duplicates.iloc[i, 1:], duplicates.iloc[j, 1:]):\n",
    "                        duplicate_pairs.append((i, j, duplicates.iloc[i, 0] == duplicates.iloc[j, 0]))  # Store (index1, index2, same_id)\n",
    "\n",
    "            similar_rows = []\n",
    "            for i, j in combinations(range(self.totalMatches(df)), 2):  # Unique row pairs\n",
    "                if is_similar(df.iloc[i, 1:], df.iloc[j, 1:]):  # Compare columns 1-5\n",
    "                    similar_rows.append((i, j))\n",
    "        \n",
    "            print(duplicate_pairs)\n",
    "            # Count same ID and different ID duplicates\n",
    "            tp = sum(1 for _, _, same_id in duplicate_pairs if same_id)\n",
    "            fp = len(duplicate_pairs) - same_id_count\n",
    "            fn = self.groundTruth.size - tp\n",
    "            \n",
    "            precision = tp / (tp + fp) if tp + fp != 0 else 0 \n",
    "            recall = tp / (tp + fn)  if tp + fn != 0 else 0\n",
    "            f1_score = (2 * precision * recall) / (precision + recall)\n",
    "            \n",
    "            print(\"Total Possible Mathces:\", self.groundTruth.size)\n",
    "            print(\"True Positives (TP):\", tp)\n",
    "            print(\"False Positives (FP):\", fp)\n",
    "            print(\"False Negatives (FN):\", fn)\n",
    "            print(\"Precision:\", f\"{precision:.4f}\")\n",
    "            print(\"Recall:\", f\"{recall:.4f}\")\n",
    "            print(\"F1-score:\", f\"{f1_score:.4f}\")\n",
    "\n",
    "        def _matchingAlgorithm(self, group):\n",
    "            return group.nunique() == 1\n",
    "            \n",
    "        def _setThresholdValues(self) -> List:\n",
    "            size = len(self.totalMatches.columns) - 1\n",
    "            limit = math.floor(self.threshold * size)\n",
    "            \n",
    "            print(f\"We accept at least {limit}/{size} as matches!\") \n",
    "            self.matchingRows = limit\n",
    "            # return [i for i in range(size, limit , -1)]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "603541e9-4f75-435c-86aa-7e45489ef7b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create two datasets with slight variations\n",
    "# Data have 3 matches and one \n",
    "data1 = {\n",
    "    0: [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "    1: [\"Kostas\", \"Maria\", \"John\", \"Sophia\", \"George\", \"Eleni\", \"Michael\", \"Anna\", \"Chris\", \"Dimitris\"],\n",
    "    2: [\"Razgkelis\", \"Papadopoulos\", \"Smith\", \"Johnson\", \"Pavlou\", \"Nikolaou\", \"Brown\", \"Miller\", \"Taylor\", \"Andreas\"],\n",
    "    3: [\"Orestiada\", \"Thessaloniki\", \"Grevena\", \"Athina\", \"Aleksandroupoli\", \"Giannena\", \"Larissa\", \"Komotini\", \"Trikala\", \"Kozani\"],\n",
    "    4: ['Jennifer Lights', 'Brandon Lakes', 'Aguilar Stravenue', 'Richardson Ferry', 'Freeman Way', \n",
    "        'Gabrielle Underpass', 'Burns Summit', 'Heather Village', 'Jamie Common', 'Greg Lock'],\n",
    "    5:  ['Cooper and Sons', 'Pope LLC', 'Fowler-Smith', 'Torres PLC', 'Jones LLC', 'White, Duncan and Robinson', 'Hayden Inc', \n",
    "         'Wilson and Sons', 'Peterson, Smith and Robinson','Hudson, Phelps and Day'],\n",
    "    \n",
    "}\n",
    "\n",
    "data2 = {\n",
    "    0: [101, 202, 203, 204, 205, 206, 207, 208, 209, 110],\n",
    "    1: [\"Kistas\", \"Maria\", \"John\", \"Sophasdia\", \"Giorge\", \"Elendsi\", \"Micheal\", \"Ana\", \"Khris\", \"Dimtris\"],\n",
    "    2: [\"Rozgkliiis\", \"Papadopoulos\", \"Smith\", \"Johnson\", \"Pavlodvu\", \"Nikolaou\", \"Batrrroun\", \"antMiler\", \"Tttayloor\", \"Andres\"],\n",
    "    3: [\"Orestiada\", \"Thessaloniki\", \"Grevena\", \"Athina\", \"Aleksandrouasdpoli\", \"Gianasdna\", \"Larasdissa\", \"Komasdini\", \"Trsadala\", \"Koxani\"],\n",
    "    4: [\"Jnnfer Lights\", 'Brandon Lakes', 'Aguilar Stravenue', 'RichardasasdaFerry', 'Freasdeman Way', 'Gabrielle Underpass', 'Burasdas mmit', 'Heatasasdllage', 'JamasdCommon', 'Grg Lck'],\n",
    "    5:  ['Cpeeer and ons', 'Pope LLC', 'Fowler-Smith', 'Torvasd PLC', 'Jonasda LLC', 'Whitasddvuncan and Robinson', 'Hayasdasv Inc', \n",
    "         'Wasdvand Sons', 'Petersosdvaith and Robinson','Htsn, Phelps and Day'],\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6b22753-5166-46e7-b4d2-b0875bc3e1e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We accept at least 2/5 as matches!\n",
      "      0     1     2     3     4     5\n",
      "12  110  D536  A536  K250  G624  H325\n",
      "13  110  D536  A536  K250  G624  H325\n",
      "4   103  J500  S530  G615  A246  F462\n",
      "5   203  J500  S530  G615  A246  F462\n",
      "0   101  K232  R242  O623  J516  C165\n",
      "1   101  K232  R242  O623  J516  C165\n",
      "2   102  M600  P131  T245  B653  P142\n",
      "3   202  M600  P131  T245  B653  P142\n",
      "[(0, 1, True), (2, 3, False), (4, 5, True), (6, 7, False)]\n",
      "Total Possible Mathces: 2\n",
      "True Positives (TP): 2\n",
      "False Positives (FP): 2\n",
      "False Negatives (FN): 0\n",
      "Precision: 0.5000\n",
      "Recall: 1.0000\n",
      "F1-score: 0.6667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert to DataFrame\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Run pipeline and see statistics\n",
    "pipeline = MyClass(df1, df2, matchColumn=0, on=[1, 2, 3, 4, 5], threshold=0.4)\n",
    "pipeline.setGroundTruth()\n",
    "pipeline.soundexDfs()\n",
    "pipeline.setTotalMatches()\n",
    "pipeline.printStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b590ab60-2d2c-431e-b8a2-81132567745b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    101\n",
      "Name: 0, dtype: int64\n",
      "0    110\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ed744a7-fed0-42a1-9375-1a97798bb0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = pipeline.totalMatches[pipeline.totalMatches[[1,2,3,4,5]].duplicated(keep=False)].sort_values(by=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c57472b1-df39-49fe-a292-e626c608b884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates.groupby([1, 2, 3, 4, 5])[0].nunique().eq(1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abf96e60-4c71-44b2-a2e3-a0e1db018055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates.groupby([1, 2, 3, 4, 5])[0].nunique().gt(1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d2014b-6f08-4937-8171-ca33dd0e6936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH  =  \"data/\"\n",
    "\n",
    "df1 = pd.read_csv(os.path.join(PATH, 'df1.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "df2 = pd.read_csv(os.path.join(PATH, 'df5.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "\n",
    "# Run pipeline and see statistics\n",
    "pipeline = MyClass(df1, df2, matchColumn=0, on=[1,2,3,4,5], method=\"column\", threshold = 0.6) #  --> this means at least 3/5 of the fields must match \n",
    "pipeline.setGroundTruth()\n",
    "pipeline.soundexDfs()\n",
    "# pipeline.setTotalMatches()\n",
    "# pipeline.printStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af5e3fb-00e7-462d-b1ec-e880e896b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pipeline.totalMatches)\n",
    "\n",
    "# Convert to NumPy array for faster computation\n",
    "data = df.iloc[:, 1:].to_numpy()  # Exclude ID column\n",
    "\n",
    "# Compute similarity matrix (all row comparisons)\n",
    "similar_matrix = np.equal(data[:, None, :], data[None, :, :]).sum(axis=2)\n",
    "\n",
    "# Find indices where at least 4 out of 5 values match (excluding self-comparisons)\n",
    "similar_pairs = np.argwhere((similar_matrix >= 4) & (np.triu(np.ones(similar_matrix.shape), k=1) == 1))\n",
    "\n",
    "# Convert result to a list of tuples (row index pairs)\n",
    "similar_rows = [tuple(pair) for pair in similar_pairs]\n",
    "\n",
    "# Display results\n",
    "print(f\"Found {len(similar_rows)} similar row pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b88128d-97ed-4832-8ef1-f1ad997eba24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13544 similar row pairs.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "data = {\n",
    "    0: [110, 110, 103, 203, 101, 101, 102, 202],  # ID column\n",
    "    1: ['D536', 'D536', 'J500', 'J500', 'K232', 'K232', 'M600', 'M600'],\n",
    "    2: ['A536', 'A536', 'S530', 'S530', 'R242', 'R232', 'P131', 'P131'],\n",
    "    3: ['K250', 'K250', 'G615', 'G615', 'O623', 'O623', 'T245', 'T245'],\n",
    "    4: ['G624', 'G624', 'A246', 'A246', 'J516', 'J516', 'B653', 'B653'],\n",
    "    5: ['H325', 'H325', 'F462', 'F462', 'C165', 'C135', 'P142', 'P142'],\n",
    "}\n",
    "\n",
    "# Convert totalMatches to DataFrame\n",
    "#df = pd.DataFrame(data)\n",
    "df = pd.DataFrame(pipeline.totalMatches)\n",
    "data = df.iloc[:, 1:].to_numpy()  # Exclude ID column\n",
    "\n",
    "# Function to compare a row against all others\n",
    "def find_similar_pairs(i):\n",
    "    matches = (np.equal(data[i], data).sum(axis=1) >= 4)  # Compare row i with all\n",
    "    return [(i, j) for j in np.where(matches)[0] if j > i]  # Store pairs (i, j)\n",
    "\n",
    "# Parallel execution\n",
    "num_jobs = -1  # Use all available CPU cores\n",
    "similar_rows = Parallel(n_jobs=num_jobs)(delayed(find_similar_pairs)(i) for i in range(len(data)))\n",
    "\n",
    "# Flatten the list\n",
    "similar_rows = [pair for sublist in similar_rows for pair in sublist]\n",
    "\n",
    "# Display results\n",
    "print(f\"Found {len(similar_rows)} similar row pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eaf96010-fe71-4730-bc53-478f358cb408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6665682220909628, 0.36112, 9028, 4516, 15972)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = 0  # False Positives\n",
    "tp = 0  # True Positives\n",
    "\n",
    "# Convert ground truth to a set for faster lookup\n",
    "ground_truth_set = pipeline.groundTruth\n",
    "\n",
    "# Iterate through similar row pairs\n",
    "for i, j in similar_rows:\n",
    "    row_i = pipeline.totalMatches.iloc[i][0]  # Convert row to tuple\n",
    "    row_j = pipeline.totalMatches.iloc[j][0]  \n",
    "\n",
    "    if row_i in ground_truth_set and row_j in ground_truth_set:  # Check if either row is in ground truth\n",
    "        tp += 1  # True Positive\n",
    "\n",
    "\n",
    "# Avoid division by zero\n",
    "fp = len(similar_rows) - tp\n",
    "fn = 25_000 - tp\n",
    "\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "precision, recall, tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19019988-dbc3-44f6-84d2-e01d5e88fdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA100000</td>\n",
       "      <td>B323</td>\n",
       "      <td>J520</td>\n",
       "      <td>A620</td>\n",
       "      <td>3523</td>\n",
       "      <td>G650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA100004</td>\n",
       "      <td>B620</td>\n",
       "      <td>M240</td>\n",
       "      <td>E421</td>\n",
       "      <td>2251</td>\n",
       "      <td>B645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA100004</td>\n",
       "      <td>B620</td>\n",
       "      <td>M240</td>\n",
       "      <td>E421</td>\n",
       "      <td>2251</td>\n",
       "      <td>B645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA100006</td>\n",
       "      <td>B620</td>\n",
       "      <td>D520</td>\n",
       "      <td>W460</td>\n",
       "      <td>3345</td>\n",
       "      <td>H616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA100007</td>\n",
       "      <td>K260</td>\n",
       "      <td>K600</td>\n",
       "      <td>L500</td>\n",
       "      <td>1225</td>\n",
       "      <td>G650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200288</th>\n",
       "      <td>AL262640</td>\n",
       "      <td>F655</td>\n",
       "      <td>E540</td>\n",
       "      <td>L200</td>\n",
       "      <td>3223</td>\n",
       "      <td>M624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200289</th>\n",
       "      <td>AL262641</td>\n",
       "      <td>T500</td>\n",
       "      <td>G625</td>\n",
       "      <td>A425</td>\n",
       "      <td>1626</td>\n",
       "      <td>A214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200290</th>\n",
       "      <td>AL262642</td>\n",
       "      <td>E430</td>\n",
       "      <td>C645</td>\n",
       "      <td>N240</td>\n",
       "      <td>1214</td>\n",
       "      <td>F432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200291</th>\n",
       "      <td>AL262643</td>\n",
       "      <td>S645</td>\n",
       "      <td>J650</td>\n",
       "      <td>W450</td>\n",
       "      <td>1263</td>\n",
       "      <td>A214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200292</th>\n",
       "      <td>AL262644</td>\n",
       "      <td>H560</td>\n",
       "      <td>C460</td>\n",
       "      <td>E421</td>\n",
       "      <td>7623</td>\n",
       "      <td>W455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200293 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1     2     3     4     5\n",
       "0       AA100000  B323  J520  A620  3523  G650\n",
       "1       AA100004  B620  M240  E421  2251  B645\n",
       "2       AA100004  B620  M240  E421  2251  B645\n",
       "3       AA100006  B620  D520  W460  3345  H616\n",
       "4       AA100007  K260  K600  L500  1225  G650\n",
       "...          ...   ...   ...   ...   ...   ...\n",
       "200288  AL262640  F655  E540  L200  3223  M624\n",
       "200289  AL262641  T500  G625  A425  1626  A214\n",
       "200290  AL262642  E430  C645  N240  1214  F432\n",
       "200291  AL262643  S645  J650  W450  1263  A214\n",
       "200292  AL262644  H560  C460  E421  7623  W455\n",
       "\n",
       "[200293 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.totalMatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a992d-74d7-4b3e-91f4-55cab029ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.6665682220909628, 0.36112, 9028, 4516, 15972)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d24669c-7a00-4d46-ab8e-568e915cd32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_similar(row1, row2, threshold=4):\n",
    "    return np.sum(row1[1:] == row2[1:]) >= threshold  # Compare columns 1-5\n",
    "\n",
    "# df1 = pd.DataFrame({\n",
    "#     0: [101, 102, 103, 104],\n",
    "#     1: ['X123', 'Y456', 'Z789', 'X123'],\n",
    "#     2: ['K250', 'G624', 'J500', 'S530'],\n",
    "#     3: ['R242', 'P131', 'T245', 'M600'],\n",
    "#     4: ['O623', 'B653', 'G615', 'A246'],\n",
    "#     5: ['J516', 'P142', 'F462', 'C165']\n",
    "# }).to_numpy()\n",
    "\n",
    "# df2 = pd.DataFrame({\n",
    "#     0: [101, 102, 203, 204],\n",
    "#     1: ['X123', 'Z789', 'Y456', 'M999'],\n",
    "#     2: ['K250', 'G624', 'S530', 'T111'],\n",
    "#     3: ['R242', 'P131', 'T245', 'M610'],\n",
    "#     4: ['O623', 'B653', 'G615', 'A256'],\n",
    "#     5: ['J516', 'P142', 'F462', 'D999']\n",
    "# }).to_numpy()\n",
    "\n",
    "# df1 = pd.concat([pipeline.df1.sample(n=750, random_state=9), pd.DataFrame(pipeline.groundTruth[:250, ]).merge(pipeline.df1, on=[0])]).to_numpy()\n",
    "# df2 = pd.concat([pipeline.df2.sample(n=750, random_state=10), pd.DataFrame(pipeline.groundTruth[:250, ]).merge(pipeline.df2, on=[0])]).to_numpy()\n",
    "\n",
    "df1 = pipeline.df1.to_numpy()\n",
    "df2 = pipeline.df2.to_numpy()\n",
    "\n",
    "# ========================================================= # \n",
    "ground_truth = np.intersect1d(df1[:, 0], df2[:, 0])\n",
    "\n",
    "\n",
    "# Create all row index pairs\n",
    "row_pairs = list(product(df1[:, 0], df2[:, 0]))\n",
    "print(row_pairs)\n",
    "\n",
    "# Compare rows and store similar ones\n",
    "totalMatches = [(id1, id2) for id1, id2 in row_pairs \n",
    "                 if is_similar(df1[df1[:, 0] == id1][0], df2[df2[:, 0] == id2][0])]\n",
    "\n",
    "\n",
    "tp = sum(1 for x, y in totalMatches if x == y and x in ground_truth)\n",
    "fp = len(totalMatches) - tp\n",
    "fn = len(ground_truth) - tp\n",
    "\n",
    "tp, fp ,fn, tp/(tp+fp), tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f61193-7dfa-4df8-aa13-db3078038007",
   "metadata": {},
   "outputs": [],
   "source": [
    "3, (169, 13, 83, 0.9285714285714286, 0.6706349206349206)\n",
    "4, (83, 0, 169, 1.0, 0.32936507936507936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434913f3-5136-4702-83b2-efcd0c1ea41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 81\n",
      "False Positives: 0\n",
      "False Negatives: 169\n",
      "Precision: 1.0000\n",
      "Recall: 0.3240\n"
     ]
    }
   ],
   "source": [
    "# Function to process chunks\n",
    "def process_chunk(chunk_row_pairs, df1, df2, ground_truth):\n",
    "    totalMatches = []\n",
    "    for id1, id2 in chunk_row_pairs:\n",
    "        if is_similar(df1[df1[:, 0] == id1][0], df2[df2[:, 0] == id2][0]):\n",
    "            totalMatches.append((id1, id2))\n",
    "\n",
    "    # Calculate tp, fp, fn for this chunk\n",
    "    tp = sum(1 for x, y in totalMatches if x == y and x in ground_truth)\n",
    "    fp = len(totalMatches) - tp\n",
    "    fn = len(ground_truth) - tp\n",
    "    \n",
    "    return tp, fp, fn\n",
    "\n",
    "def is_similar(row1, row2, threshold=4):\n",
    "    return np.sum(row1[1:] == row2[1:]) >= threshold  # Compare columns 1-5\n",
    "\n",
    "\n",
    "df1 = pd.concat([pipeline.df1.iloc[:250], pipeline.df1.iloc[25_000:25000 + 750]]).to_numpy()\n",
    "df2 = pd.concat([pipeline.df2.iloc[:250], pipeline.df2.iloc[25_000:25000 + 750]]).to_numpy()\n",
    "\n",
    "ground_truth = np.intersect1d(df1[:, 0], df2[:, 0])\n",
    "\n",
    "# Split row pairs into chunks\n",
    "chunk_size = 1000  # Adjust chunk size based on memory and performance\n",
    "\n",
    "# Process in chunks\n",
    "total_tp, total_fp, total_fn = 0, 0, 0\n",
    "for i in range(0, len(df1), chunk_size):\n",
    "    # Generate row pairs for the current chunk\n",
    "    chunk_row_pairs = list(product(df1[i:i + chunk_size, 0], df2[:, 0]))\n",
    "    print(chunk_row_pairs)# Create pairs of IDs from the current chunk\n",
    "    tp, fp, fn = process_chunk(chunk_row_pairs, df1, df2, ground_truth)\n",
    "    \n",
    "    total_tp += tp\n",
    "    total_fp += fp\n",
    "    total_fn += fn\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = total_tp / (total_tp + total_fp) if total_tp + total_fp > 0 else 0\n",
    "recall = total_tp / (total_tp + total_fn) if total_tp + total_fn > 0 else 0\n",
    "\n",
    "print(f\"True Positives: {total_tp}\")\n",
    "print(f\"False Positives: {total_fp}\")\n",
    "print(f\"False Negatives: {total_fn}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff153e9-8134-4db8-bddf-edac31f7f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14c5636f-3a0d-46cb-97c1-3691cfe54de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7500.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30_000* 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40814635-69ef-48b4-a287-84d29730fa3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA100000</td>\n",
       "      <td>B323</td>\n",
       "      <td>J520</td>\n",
       "      <td>A620</td>\n",
       "      <td>3523</td>\n",
       "      <td>G650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA100004</td>\n",
       "      <td>B620</td>\n",
       "      <td>M240</td>\n",
       "      <td>E421</td>\n",
       "      <td>2251</td>\n",
       "      <td>B645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA100006</td>\n",
       "      <td>B620</td>\n",
       "      <td>D520</td>\n",
       "      <td>W460</td>\n",
       "      <td>3345</td>\n",
       "      <td>H616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA100007</td>\n",
       "      <td>K260</td>\n",
       "      <td>K600</td>\n",
       "      <td>L500</td>\n",
       "      <td>1225</td>\n",
       "      <td>G650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA100008</td>\n",
       "      <td>K536</td>\n",
       "      <td>J600</td>\n",
       "      <td>F652</td>\n",
       "      <td>4235</td>\n",
       "      <td>B645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32495</th>\n",
       "      <td>AA166533</td>\n",
       "      <td>F600</td>\n",
       "      <td>G620</td>\n",
       "      <td>E620</td>\n",
       "      <td>2262</td>\n",
       "      <td>G650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32496</th>\n",
       "      <td>AA166534</td>\n",
       "      <td>D200</td>\n",
       "      <td>R263</td>\n",
       "      <td>W240</td>\n",
       "      <td>1143</td>\n",
       "      <td>M150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32497</th>\n",
       "      <td>AA166535</td>\n",
       "      <td>R500</td>\n",
       "      <td>A500</td>\n",
       "      <td>R200</td>\n",
       "      <td>2552</td>\n",
       "      <td>G654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32498</th>\n",
       "      <td>AA166537</td>\n",
       "      <td>P200</td>\n",
       "      <td>K200</td>\n",
       "      <td>R120</td>\n",
       "      <td>2645</td>\n",
       "      <td>B645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32499</th>\n",
       "      <td>AA166539</td>\n",
       "      <td>C230</td>\n",
       "      <td>K365</td>\n",
       "      <td>B236</td>\n",
       "      <td>5262</td>\n",
       "      <td>G650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0     1     2     3     4     5\n",
       "0      AA100000  B323  J520  A620  3523  G650\n",
       "1      AA100004  B620  M240  E421  2251  B645\n",
       "2      AA100006  B620  D520  W460  3345  H616\n",
       "3      AA100007  K260  K600  L500  1225  G650\n",
       "4      AA100008  K536  J600  F652  4235  B645\n",
       "...         ...   ...   ...   ...   ...   ...\n",
       "32495  AA166533  F600  G620  E620  2262  G650\n",
       "32496  AA166534  D200  R263  W240  1143  M150\n",
       "32497  AA166535  R500  A500  R200  2552  G654\n",
       "32498  AA166537  P200  K200  R120  2645  B645\n",
       "32499  AA166539  C230  K365  B236  5262  G650\n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e92305c0-ca65-4662-bde2-e203dd554b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA100000</td>\n",
       "      <td>B325</td>\n",
       "      <td>J500</td>\n",
       "      <td>A620</td>\n",
       "      <td>3523</td>\n",
       "      <td>G665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA100004</td>\n",
       "      <td>B620</td>\n",
       "      <td>M240</td>\n",
       "      <td>E421</td>\n",
       "      <td>2251</td>\n",
       "      <td>B645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA100006</td>\n",
       "      <td>B620</td>\n",
       "      <td>D500</td>\n",
       "      <td>W460</td>\n",
       "      <td>3345</td>\n",
       "      <td>H616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA100007</td>\n",
       "      <td>K260</td>\n",
       "      <td>K600</td>\n",
       "      <td>L520</td>\n",
       "      <td>1221</td>\n",
       "      <td>G650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA100008</td>\n",
       "      <td>K562</td>\n",
       "      <td>J560</td>\n",
       "      <td>F652</td>\n",
       "      <td>4235</td>\n",
       "      <td>B642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>AA107434</td>\n",
       "      <td>T260</td>\n",
       "      <td>L200</td>\n",
       "      <td>S163</td>\n",
       "      <td>2241</td>\n",
       "      <td>G650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>AA107436</td>\n",
       "      <td>V654</td>\n",
       "      <td>G000</td>\n",
       "      <td>A535</td>\n",
       "      <td>1265</td>\n",
       "      <td>B642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>AA107439</td>\n",
       "      <td>W426</td>\n",
       "      <td>E600</td>\n",
       "      <td>G453</td>\n",
       "      <td>2252</td>\n",
       "      <td>G654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>AA107440</td>\n",
       "      <td>H626</td>\n",
       "      <td>L260</td>\n",
       "      <td>J215</td>\n",
       "      <td>1261</td>\n",
       "      <td>E400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>AA107441</td>\n",
       "      <td>H626</td>\n",
       "      <td>M650</td>\n",
       "      <td>D420</td>\n",
       "      <td>1262</td>\n",
       "      <td>E451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1     2     3     4     5\n",
       "0     AA100000  B325  J500  A620  3523  G665\n",
       "1     AA100004  B620  M240  E421  2251  B645\n",
       "2     AA100006  B620  D500  W460  3345  H616\n",
       "3     AA100007  K260  K600  L520  1221  G650\n",
       "4     AA100008  K562  J560  F652  4235  B642\n",
       "...        ...   ...   ...   ...   ...   ...\n",
       "2495  AA107434  T260  L200  S163  2241  G650\n",
       "2496  AA107436  V654  G000  A535  1265  B642\n",
       "2497  AA107439  W426  E600  G453  2252  G654\n",
       "2498  AA107440  H626  L260  J215  1261  E400\n",
       "2499  AA107441  H626  M650  D420  1262  E451\n",
       "\n",
       "[2500 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.df2.iloc[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370fd24f-2174-4c55-b124-ad7db2765a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
